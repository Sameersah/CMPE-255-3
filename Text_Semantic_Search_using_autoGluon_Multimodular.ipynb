{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1GpZHWOr+Fzb3uIWBaBQa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sameersah/CMPE-255-3/blob/main/Text_Semantic_Search_using_autoGluon_Multimodular.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WaIfRC0GJ3Zn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbtbvibgJhbu"
      },
      "outputs": [],
      "source": [
        "!pip install autogluon.multimodal"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0ssOr42tJ4Yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip3 install ir_datasets\n",
        "import ir_datasets\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "id": "vKC19YM-J4cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "c_frZJSeJ70i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "dataset = ir_datasets.load(\"beir/nfcorpus/test\")\n",
        "\n",
        "# prepare dataset\n",
        "doc_data = pd.DataFrame(dataset.docs_iter())\n",
        "query_data = pd.DataFrame(dataset.queries_iter())\n",
        "labeled_data = pd.DataFrame(dataset.qrels_iter())\n",
        "label_col = \"relevance\"\n",
        "query_id_col = \"query_id\"\n",
        "doc_id_col = \"doc_id\"\n",
        "text_col = \"text\"\n",
        "id_mappings={query_id_col: query_data.set_index(query_id_col)[text_col], doc_id_col: doc_data.set_index(doc_id_col)[text_col]}"
      ],
      "metadata": {
        "id": "g1H0KwMOJ78Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "njEM_NjYJ93o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_data.head()"
      ],
      "metadata": {
        "id": "AALz2fngJ97l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C6CifiLxJ-iF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_data.head()"
      ],
      "metadata": {
        "id": "L5zUB00FJ-ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "huTfmAC0KByJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_data = query_data.drop(\"url\", axis=1)\n",
        "query_data.head()"
      ],
      "metadata": {
        "id": "XhMs7clEKB2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eBKsrTYoKD4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc_data.head(1)"
      ],
      "metadata": {
        "id": "-MwpSjetKD91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sNSEzUvIKFuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc_data[text_col] = doc_data[[text_col, \"title\"]].apply(\" \".join, axis=1)\n",
        "doc_data = doc_data.drop([\"title\", \"url\"], axis=1)\n",
        "doc_data.head(1)"
      ],
      "metadata": {
        "id": "ge7-AMjjKF1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "f2Y8nE8mKPfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.multimodal.utils import compute_ranking_score\n",
        "cutoffs = [5, 10, 20]"
      ],
      "metadata": {
        "id": "uwjj1xffKPkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eKAzNezrKSci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip3 install rank_bm25\n",
        "from collections import defaultdict\n",
        "import string\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "def tokenize_corpus(corpus):\n",
        "    stop_words = set(stopwords.words(\"english\") + list(string.punctuation))\n",
        "\n",
        "    tokenized_docs = []\n",
        "    for doc in corpus:\n",
        "        tokens = nltk.word_tokenize(doc.lower())\n",
        "        tokenized_doc = [w for w in tokens if w not in stop_words and len(w) > 2]\n",
        "        tokenized_docs.append(tokenized_doc)\n",
        "    return tokenized_docs\n",
        "\n",
        "def rank_documents_bm25(queries_text, queries_id, docs_id, top_k, bm25):\n",
        "    tokenized_queries = tokenize_corpus(queries_text)\n",
        "\n",
        "    results = {qid: {} for qid in queries_id}\n",
        "    for query_idx, query in enumerate(tokenized_queries):\n",
        "        scores = bm25.get_scores(query)\n",
        "        scores_top_k_idx = np.argsort(scores)[::-1][:top_k]\n",
        "        for doc_idx in scores_top_k_idx:\n",
        "            results[queries_id[query_idx]][docs_id[doc_idx]] = float(scores[doc_idx])\n",
        "    return results\n",
        "\n",
        "def get_qrels(dataset):\n",
        "    \"\"\"\n",
        "    Get the ground truth of relevance score for all queries\n",
        "    \"\"\"\n",
        "    qrel_dict = defaultdict(dict)\n",
        "    for qrel in dataset.qrels_iter():\n",
        "        qrel_dict[qrel.query_id][qrel.doc_id] = qrel.relevance\n",
        "    return qrel_dict\n",
        "\n",
        "def evaluate_bm25(doc_data, query_data, qrel_dict, cutoffs):\n",
        "\n",
        "    tokenized_corpus = tokenize_corpus(doc_data[text_col].tolist())\n",
        "    bm25_model = BM25Okapi(tokenized_corpus, k1=1.2, b=0.75)\n",
        "\n",
        "    results = rank_documents_bm25(query_data[text_col].tolist(), query_data[query_id_col].tolist(), doc_data[doc_id_col].tolist(), max(cutoffs), bm25_model)\n",
        "    ndcg = compute_ranking_score(results=results, qrel_dict=qrel_dict, metrics=[\"ndcg\"], cutoffs=cutoffs)\n",
        "\n",
        "    return ndcg"
      ],
      "metadata": {
        "id": "nrtbowprKShu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EHeFDjOpKUiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qrel_dict = get_qrels(dataset)\n",
        "evaluate_bm25(doc_data, query_data, qrel_dict, cutoffs)"
      ],
      "metadata": {
        "id": "kV4xLnLPKUox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "J1-95b-HKZEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%capture\n",
        "from autogluon.multimodal import MultiModalPredictor\n",
        "\n",
        "predictor = MultiModalPredictor(\n",
        "        query=query_id_col,\n",
        "        response=doc_id_col,\n",
        "        label=label_col,\n",
        "        problem_type=\"text_similarity\",\n",
        "        hyperparameters={\"model.hf_text.checkpoint_name\": \"sentence-transformers/all-MiniLM-L6-v2\"}\n",
        "    )"
      ],
      "metadata": {
        "id": "xeSi_AgAKZIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5rNKlVCVKcP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.evaluate(\n",
        "        labeled_data,\n",
        "        query_data=query_data[[query_id_col]],\n",
        "        response_data=doc_data[[doc_id_col]],\n",
        "        id_mappings=id_mappings,\n",
        "        cutoffs=cutoffs,\n",
        "        metrics=[\"ndcg\"],\n",
        "    )"
      ],
      "metadata": {
        "id": "2Q2BGSjKKcUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pc5gQoQnKeYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.multimodal.utils import semantic_search\n",
        "hits = semantic_search(\n",
        "        matcher=predictor,\n",
        "        query_data=query_data[text_col].tolist(),\n",
        "        response_data=doc_data[text_col].tolist(),\n",
        "        query_chunk_size=len(query_data),\n",
        "        top_k=max(cutoffs),\n",
        "    )"
      ],
      "metadata": {
        "id": "4c51DvWqKecv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3LS7W08qKiN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_embeds = predictor.extract_embedding(query_data[[query_id_col]], id_mappings=id_mappings, as_tensor=True)\n",
        "doc_embeds = predictor.extract_embedding(doc_data[[doc_id_col]], id_mappings=id_mappings, as_tensor=True)"
      ],
      "metadata": {
        "id": "56Ggk8UAKiTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FnIyJg1dKlkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from autogluon.multimodal.utils import compute_semantic_similarity\n",
        "\n",
        "def hybridBM25(query_data, query_embeds, doc_data, doc_embeds, recall_num, top_k, beta):\n",
        "    # Recall documents with BM25 scores\n",
        "    tokenized_corpus = tokenize_corpus(doc_data[text_col].tolist())\n",
        "    bm25_model = BM25Okapi(tokenized_corpus, k1=1.2, b=0.75)\n",
        "    bm25_scores = rank_documents_bm25(query_data[text_col].tolist(), query_data[query_id_col].tolist(), doc_data[doc_id_col].tolist(), recall_num, bm25_model)\n",
        "\n",
        "    all_bm25_scores = [score for scores in bm25_scores.values() for score in scores.values()]\n",
        "    max_bm25_score = max(all_bm25_scores)\n",
        "    min_bm25_score = min(all_bm25_scores)\n",
        "\n",
        "    q_embeddings = {qid: embed for qid, embed in zip(query_data[query_id_col].tolist(), query_embeds)}\n",
        "    d_embeddings = {did: embed for did, embed in zip(doc_data[doc_id_col].tolist(), doc_embeds)}\n",
        "\n",
        "    query_ids = query_data[query_id_col].tolist()\n",
        "    results = {qid: {} for qid in query_ids}\n",
        "    for idx, qid in enumerate(query_ids):\n",
        "        rec_docs = bm25_scores[qid]\n",
        "        rec_doc_emb = [d_embeddings[doc_id] for doc_id in rec_docs.keys()]\n",
        "        rec_doc_id = [doc_id for doc_id in rec_docs.keys()]\n",
        "        rec_doc_emb = torch.stack(rec_doc_emb)\n",
        "        scores = compute_semantic_similarity(q_embeddings[qid], rec_doc_emb)\n",
        "        scores[torch.isnan(scores)] = -1\n",
        "        top_k_values, top_k_idxs = torch.topk(\n",
        "            scores,\n",
        "            min(top_k + 1, len(scores[0])),\n",
        "            dim=1,\n",
        "            largest=True,\n",
        "            sorted=False,\n",
        "        )\n",
        "\n",
        "        for doc_idx, score in zip(top_k_idxs[0], top_k_values[0]):\n",
        "            doc_id = rec_doc_id[int(doc_idx)]\n",
        "            # Hybrid scores from BM25 and cosine similarity of embeddings\n",
        "            results[qid][doc_id] = \\\n",
        "                (1 - beta) * float(score.numpy()) \\\n",
        "                + beta * (bm25_scores[qid][doc_id] - min_bm25_score) / (max_bm25_score - min_bm25_score)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def evaluate_hybridBM25(query_data, query_embeds, doc_data, doc_embeds, recall_num, beta, cutoffs):\n",
        "    results = hybridBM25(query_data, query_embeds, doc_data, doc_embeds, recall_num, max(cutoffs), beta)\n",
        "    ndcg = compute_ranking_score(results=results, qrel_dict=qrel_dict, metrics=[\"ndcg\"], cutoffs=cutoffs)\n",
        "    return ndcg"
      ],
      "metadata": {
        "id": "7dw6q3RQKlon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "73aukyZwKoU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recall_num = 1000\n",
        "beta = 0.3\n",
        "query_embeds = predictor.extract_embedding(query_data[[query_id_col]], id_mappings=id_mappings, as_tensor=True)\n",
        "doc_embeds = predictor.extract_embedding(doc_data[[doc_id_col]], id_mappings=id_mappings, as_tensor=True)\n",
        "evaluate_hybridBM25(query_data, query_embeds, doc_data, doc_embeds, recall_num, beta, cutoffs)"
      ],
      "metadata": {
        "id": "HJtNC3Y0KoZY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}